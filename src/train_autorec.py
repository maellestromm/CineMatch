import json
import sqlite3

import matplotlib.pyplot as plt
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset


# ==========================================
# 1. æ ¸å¿ƒç¥ç»ç½‘ç»œæ¶æ„ (Deep AutoRec)
# ==========================================
class DeepAutoRec(nn.Module):
    def __init__(self, num_movies):
        super(DeepAutoRec, self).__init__()
        # æ¼æ–—å‹ç‰¹å¾å‹ç¼©ï¼šæå…¶é€‚åˆæŠ“å–ç”µå½±é—´çš„éçº¿æ€§å…³è”
        self.encoder = nn.Sequential(
            nn.Linear(num_movies, 512),
            nn.Dropout(0.3),
            nn.ReLU(),
            nn.Linear(512, 128),
            nn.Sigmoid()
        )
        self.decoder = nn.Sequential(
            nn.Linear(128, 512),
            nn.ReLU(),
            nn.Linear(512, num_movies)
        )

    def forward(self, x):
        return self.decoder(self.encoder(x))


# ==========================================
# 2. æ©ç å‡æ–¹è¯¯å·® (Masked MSE Loss)
# ==========================================
def masked_mse_loss(predictions, targets):
    mask = (targets != 0).float()
    error = (predictions - targets) * mask
    loss = (error ** 2).sum() / (mask.sum() + 1e-8)
    return loss


# ==========================================
# 3. æå…¶ä¸¥è°¨çš„æ•°æ®åŠ è½½ä¸ç»´åº¦å¯¹é½
# ==========================================
def load_and_align_data(train_db="train_model.db", test_db="test_eval.db"):
    print("ğŸ“¥ æ­£åœ¨è¯»å–å¹¶å¯¹é½ç‰©ç†éš”ç¦»çš„æ•°æ®åº“...")

    # --- åŠ è½½è®­ç»ƒé›† ---
    conn_train = sqlite3.connect(train_db)
    df_train = pd.read_sql_query(
        "SELECT user_username, movie_slug, rating FROM reviews WHERE rating != 'None' AND rating IS NOT NULL",
        conn_train)
    conn_train.close()
    df_train['rating'] = df_train['rating'].astype(float)
    matrix_train = df_train.pivot(index='user_username', columns='movie_slug', values='rating').fillna(0)

    # ç¡®ç«‹å…¨å±€çš„â€œæ ‡å‡†ç­”é¢˜å¡â€ç”µå½±ç»´åº¦
    movie_slugs = matrix_train.columns.tolist()
    num_movies = len(movie_slugs)

    # --- åŠ è½½æµ‹è¯•é›† ---
    conn_test = sqlite3.connect(test_db)
    df_test = pd.read_sql_query(
        "SELECT user_username, movie_slug, rating FROM reviews WHERE rating != 'None' AND rating IS NOT NULL",
        conn_test)
    conn_test.close()
    df_test['rating'] = df_test['rating'].astype(float)
    matrix_test = df_test.pivot(index='user_username', columns='movie_slug', values='rating').fillna(0)

    # âš¡ æ ¸å¿ƒé­”æ³•ï¼šå¼ºåˆ¶æµ‹è¯•é›†å¯¹é½è®­ç»ƒé›†çš„åˆ— (è‡ªåŠ¨è¡¥é½ç¼ºå¤±ç”µå½±ï¼Œä¸¢å¼ƒå¤šä½™ç”µå½±)
    matrix_test = matrix_test.reindex(columns=movie_slugs, fill_value=0.0)

    print(f"âœ… æ•°æ®çŸ©é˜µæ„å»ºå®Œæ¯•ï¼")
    print(f"   ğŸ¯ è®­ç»ƒé›† (Train): {matrix_train.shape[0]} ç”¨æˆ· x {num_movies} ç”µå½±")
    print(f"   ğŸ§ª æµ‹è¯•é›† (Test) : {matrix_test.shape[0]} ç”¨æˆ· x {num_movies} ç”µå½±")

    # è½¬æ¢ä¸º PyTorch å¼ é‡
    train_tensor = torch.FloatTensor(matrix_train.values)
    test_tensor = torch.FloatTensor(matrix_test.values)

    return train_tensor, test_tensor, movie_slugs


# ==========================================
# 4. å¸¦æœ‰ Early Stopping çš„å®Œç¾è®­ç»ƒå¾ªç¯
# ==========================================
def train_model(epochs=100, batch_size=256, lr=0.005, patience=8):
    # 1. è·å–å¯¹é½åçš„æ•°æ®
    train_tensor, test_tensor, movie_slugs = load_and_align_data()
    num_movies = len(movie_slugs)

    # ä¿å­˜å­—å…¸ä¾›æœªæ¥æ¨ç†ä½¿ç”¨
    with open("movie_dictionary.json", "w", encoding="utf-8") as f:
        json.dump(movie_slugs, f)

    # åŒ…è£… DataLoader
    train_dataset = TensorDataset(train_tensor, train_tensor)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # æµ‹è¯•é›†ä¸€æ¬¡æ€§å¡è¿›å»ç®—å°±è¡Œï¼Œä¸éœ€è¦åˆ† batch
    test_x = test_tensor
    test_y = test_tensor

    model = DeepAutoRec(num_movies=num_movies)
    optimizer = optim.Adam(model.parameters(), lr=lr)

    train_losses = []
    val_losses = []

    best_val_loss = float('inf')
    epochs_no_improve = 0
    best_epoch = 0

    print("\nğŸš€ å¼€å§‹ä¸¥è°¨çš„æ·±åº¦å­¦ä¹ ç‚¼ä¸¹ (ç›‘æ§ Test Loss é˜²è¿‡æ‹Ÿåˆ)...")

    for epoch in range(epochs):
        # --- è®­ç»ƒé˜¶æ®µ (é—­å·å­¦ä¹ ) ---
        model.train()
        total_train_loss = 0
        for batch_x, batch_y in train_loader:
            optimizer.zero_grad()
            preds = model(batch_x)
            loss = masked_mse_loss(preds, batch_y)
            loss.backward()
            optimizer.step()
            total_train_loss += loss.item()

        avg_train_loss = total_train_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        # --- éªŒè¯é˜¶æ®µ (å¼€å·è€ƒè¯•ï¼Œå®Œå…¨ä¸å‚ä¸åå‘ä¼ æ’­) ---
        model.eval()
        with torch.no_grad():
            test_preds = model(test_x)
            val_loss = masked_mse_loss(test_preds, test_y).item()
            val_losses.append(val_loss)

        print(f"   Epoch [{epoch + 1:03d}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Test Loss: {val_loss:.4f}")

        # --- Early Stopping é€»è¾‘ ---
        if val_loss < best_val_loss - 0.0005:  # Test Loss æ˜¾è‘—ä¸‹é™
            best_val_loss = val_loss
            epochs_no_improve = 0
            best_epoch = epoch + 1
            # åªæœ‰åˆ›çºªå½•æ—¶ï¼Œæ‰æŠŠæƒé‡å­˜åˆ°ç¡¬ç›˜ä¸Šï¼
            torch.save(model.state_dict(), "autorec_best_weights.pth")
        else:
            epochs_no_improve += 1

        if epochs_no_improve >= patience:
            print(f"\nğŸ›‘ è§¦å‘ Early Stoppingï¼æµ‹è¯•é›†è¯¯å·®åœ¨è¿ç»­ {patience} è½®æœªæ”¹å–„ã€‚")
            print(f"ğŸ† æœ€ä½³æ¨¡å‹åœç•™åœ¨ Epoch {best_epoch}ï¼ŒTest Loss ä¸º {best_val_loss:.4f}")
            break

    # ==========================================
    # 5. ç”Ÿæˆæå…¶ä¸“ä¸šçš„åŒçº¿ Loss æ›²çº¿å›¾
    # ==========================================
    plt.figure(figsize=(10, 6))
    actual_epochs = len(train_losses)

    # ç”»ä¸¤æ¡çº¿ï¼šä¸€æ¡è®­ç»ƒï¼Œä¸€æ¡æµ‹è¯•
    plt.plot(range(1, actual_epochs + 1), train_losses, label='Train Loss (5457 Users)', color='#1f77b4', linewidth=2)
    plt.plot(range(1, actual_epochs + 1), val_losses, label='Test/Val Loss (606 Users)', color='#ff7f0e', linewidth=2,
             linestyle='--')

    # æ ‡è®°å‡ºæœ€ä½³çš„é‚£ä¸ªç‚¹
    plt.axvline(x=best_epoch, color='r', linestyle=':', label=f'Best Epoch ({best_epoch})')
    plt.scatter(best_epoch, best_val_loss, color='red', zorder=5)

    plt.title('Deep AutoRec Generalization: Train vs Test Loss', fontsize=14, fontweight='bold')
    plt.xlabel('Epochs', fontsize=12)
    plt.ylabel('Masked MSE Loss', fontsize=12)
    plt.legend(fontsize=11)
    plt.grid(True, linestyle='--', alpha=0.6)

    plt.savefig('train_vs_test_loss.png', dpi=300, bbox_inches='tight')
    print("\nğŸ“ˆ ç¥çº§åŒè½¨ Loss æ›²çº¿å·²ä¿å­˜ä¸º train_vs_test_loss.png (è¯·åŠ¡å¿…æ”¾è¿›ä½ ä»¬çš„æœŸæœ« PPTï¼)")


if __name__ == "__main__":
    train_model(epochs=150, batch_size=256, lr=0.0005, patience=15)