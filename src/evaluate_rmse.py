import math
import random
import sqlite3

import numpy as np
import pandas as pd

from content_knn import ContentBasedRecommender
from infer_autorec import AutoRecRecommender
from user_knn_gpu import UserBasedRecommender

# --- é…ç½® ---
TRAIN_DB = "train_model.db"
TEST_DB = "test_eval.db"
HIDE_RATIO = 0.2


def run_rmse_evaluation():
    print("ğŸ¥Š --- Agnostic Multi-Model RMSE Benchmark (1-5 Star Accuracy) --- ğŸ¥Š\n")

    # ==========================================
    # 1. æ¨¡å‹æ³¨å†Œè¡¨ (é»‘ç›’æ¨¡å¼)
    # æµ‹è¯•è„šæœ¬ä¸å…³å¿ƒåº•å±‚å®ç°ï¼Œåªè®¤ get_recommendations æ¥å£ï¼
    # ==========================================
    print("[Eval] Initializing models (Black-box mode)...")
    models = {
        "User-KNN": UserBasedRecommender(db_path=TRAIN_DB),
        "Content-KNN": ContentBasedRecommender(db_path=TRAIN_DB),
        "Deep AutoRec": AutoRecRecommender(db_path=TRAIN_DB)
        # æœªæ¥åŠ æ–°æ¨¡å‹ç›´æ¥å†™åœ¨è¿™é‡Œ
    }

    metrics = {name: [] for name in models}

    print("\n[Eval] Loading test subjects from Test DB...")
    conn = sqlite3.connect(TEST_DB)
    df_test = pd.read_sql_query("SELECT user_username, movie_slug, rating FROM reviews WHERE rating != 'None'", conn)
    df_test['rating'] = pd.to_numeric(df_test['rating'], errors='coerce').dropna()
    conn.close()

    test_users = df_test['user_username'].unique()
    valid_users = 0

    for i, user in enumerate(test_users, 1):
        user_data = df_test[df_test['user_username'] == user]

        if len(user_data) < 5:
            continue

        all_movies = user_data['movie_slug'].tolist()
        hidden_count = max(1, int(len(all_movies) * HIDE_RATIO))

        test_set_slugs = random.sample(all_movies, hidden_count)
        train_data = user_data[~user_data['movie_slug'].isin(test_set_slugs)]
        train_profile = dict(zip(train_data['movie_slug'], train_data['rating']))
        user_avg = train_data['rating'].mean() if not train_data.empty else 3.0

        # ==========================================
        # 2. æ ¸å¿ƒè¯„ä¼°å¾ªç¯ï¼šçº¯æ¥å£è°ƒç”¨ï¼Œæ— ä»»ä½•ç¡¬ç¼–ç 
        # ==========================================
        for model_name, model in models.items():
            # è¯·æ±‚æå¤§çš„ top_nï¼Œç›¸å½“äºè®©æ¨¡å‹äº¤å‡ºå®ƒå¯¹æ‰€æœ‰å‰©ä½™ç”µå½±çš„â€œé¢„æµ‹å·å­â€
            raw_recs = model.get_recommendations(train_profile, top_n=3334)

            # å°†å·å­è½¬ä¸º O(1) æŸ¥è¯¢çš„å­—å…¸: {slug: score}
            pred_dict = {rec['slug']: rec['score'] for rec in raw_recs}

            # å¼€å§‹å¯¹éšè—ç”µå½±è¿›è¡Œæ‰¹æ”¹
            for hidden_slug in test_set_slugs:
                actual_rating = float(user_data[user_data['movie_slug'] == hidden_slug]['rating'].values[0])

                # å¦‚æœæ¨¡å‹é¢„æµ‹äº†è¿™éƒ¨ç”µå½±ï¼Œæ‹¿åˆ†æ•°ï¼›å¦‚æœæ¨¡å‹æ ¹æœ¬æ‰¾ä¸åˆ°ï¼ˆå†·å¯åŠ¨ï¼‰ï¼Œç”¨è¯¥ç”¨æˆ·çš„å†å²å‡åˆ†å…œåº•
                pred_rating = pred_dict.get(hidden_slug, user_avg)

                # è®°å½•è¯¯å·®å¹³æ–¹
                metrics[model_name].append((pred_rating - actual_rating) ** 2)

        valid_users += 1
        if valid_users % 50 == 0:
            print(f"[{valid_users}] Users evaluated... (Tracking RMSE for {len(models)} models)")

    # ==========================================
    # 3. æ‰“å°æœ€ç»ˆå­¦æœ¯æˆç»©å•
    # ==========================================
    print("\n" + "=" * 55)
    print("ğŸ† RMSE ACCURACY LEADERBOARD (Lower is Better) ğŸ†")
    print(f"Hidden ratings evaluated per model: {len(metrics[list(models.keys())[0]])}")
    print("=" * 55)
    print(f"{'Model Name':<18} | {'RMSE Score':<15} | {'Status'}")
    print("-" * 55)

    final_rmses = {name: math.sqrt(np.mean(errors)) for name, errors in metrics.items() if len(errors) > 0}
    sorted_rmses = sorted(final_rmses.items(), key=lambda x: x[1])

    for rank, (name, rmse) in enumerate(sorted_rmses):
        status = "ğŸ‘‘ Champion" if rank == 0 else "ğŸ’ª Runner-up" if rank == 1 else ""
        print(f" {name:<17} | {rmse:<15.4f} | {status}")

    print("=" * 55)


if __name__ == "__main__":
    run_rmse_evaluation()