import sqlite3
import pandas as pd
import torch
import torch.nn as nn
import json
import numpy as np


# ==========================================
# 1. ç½‘ç»œç»“æ„å®šä¹‰ (å¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
# ==========================================
class DeepAutoRec(nn.Module):
    def __init__(self, num_movies):
        super(DeepAutoRec, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(num_movies, 512),
            nn.Dropout(0.3),  # æ¨ç†æ—¶(model.eval)ä¼šè‡ªåŠ¨å¤±æ•ˆ
            nn.ReLU(),
            nn.Linear(512, 128),
            nn.Sigmoid()
        )
        self.decoder = nn.Sequential(
            nn.Linear(128, 512),
            nn.ReLU(),
            nn.Linear(512, num_movies)
        )

    def forward(self, x):
        return self.decoder(self.encoder(x))


# ==========================================
# 2. æ¨èå™¨å°è£… (å®Œå…¨å¯¹é½ UserBasedRecommender)
# ==========================================
class AutoRecRecommender:
    def __init__(self, db_path, dict_path="movie_dictionary.json", weights_path="autorec_best_weights.pth"):
        self.db_path = db_path
        self.df_movies = None
        self.movie_slugs = []
        self.movie_to_idx = {}
        self.num_movies = 0
        self.model = None

        # å®ä¾‹åŒ–æ—¶è‡ªåŠ¨åŠ è½½æ•°æ®å’Œæ¨¡å‹
        self._load_data(dict_path, weights_path)

    def _load_data(self, dict_path, weights_path):
        """åŠ è½½ç”µå½±å…ƒæ•°æ®ã€æ¨¡å‹å­—å…¸å’Œæƒé‡"""
        print("[AutoRec] Loading movie metadata from database...")
        conn = sqlite3.connect(self.db_path)
        query_movies = "SELECT slug, title, year, director, poster_url FROM movies"
        self.df_movies = pd.read_sql_query(query_movies, conn).set_index('slug')
        conn.close()

        print("[AutoRec] Loading model dictionary and weights...")
        try:
            with open(dict_path, "r", encoding="utf-8") as f:
                self.movie_slugs = json.load(f)
        except FileNotFoundError:
            raise Exception(f"âŒ æ‰¾ä¸åˆ°å­—å…¸æ–‡ä»¶ {dict_path}ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ï¼")

        self.num_movies = len(self.movie_slugs)
        self.movie_to_idx = {slug: idx for idx, slug in enumerate(self.movie_slugs)}

        # åˆå§‹åŒ–æ¨¡å‹å¹¶åŠ è½½æƒé‡ (map_location='cpu' ä¿è¯æ²¡æœ‰æ˜¾å¡ä¹Ÿèƒ½æé€Ÿè·‘)
        self.model = DeepAutoRec(num_movies=self.num_movies)
        try:
            self.model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))
        except FileNotFoundError:
            raise Exception(f"âŒ æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ {weights_path}ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ï¼")

        self.model.eval()  # ğŸš¨ æå…¶é‡è¦ï¼šåˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼
        print(f"[AutoRec] Engine ready! {self.num_movies} movies loaded.\n")

    def get_recommendations(self, user_profile, top_n=10):
        """
        å’Œ User-KNN æ‹¥æœ‰å®Œå…¨ä¸€è‡´çš„ç­¾åå’Œè¿”å›æ ¼å¼
        :param user_profile: dict, e.g., {'movie-slug': 5.0, 'another-slug': 4.0}
        :param top_n: int, è¿”å›çš„æ¨èæ•°é‡
        :return: list of dicts representing recommended movies
        """
        if self.model is None:
            return []

        # 1. åˆ›å»ºä¸€å¼  3334 ç»´çš„ç©ºç™½ç­”é¢˜å¡
        target_vector = torch.zeros(self.num_movies)
        watched_indices = []

        # 2. å¡«å…¥æ•™æˆ/ç”¨æˆ·æ‰“çš„åˆ†æ•°
        for slug, rating in user_profile.items():
            if slug in self.movie_to_idx:
                idx = self.movie_to_idx[slug]
                target_vector[idx] = float(rating)
                watched_indices.append(idx)
            else:
                print(f"[AutoRec] Warning: '{slug}' not found in model dictionary.")

        if target_vector.sum() == 0:
            print("[AutoRec] Warning: None of the input movies are in the database.")
            return []

        # å°† 1D æ•°ç»„å‡ç»´æˆ (1, 3334)
        target_vector = target_vector.unsqueeze(0)

        # 3. ç¬é—´æ¨ç†
        with torch.no_grad():
            predictions = self.model(target_vector).squeeze(0).numpy()

        # 4. å¼ºè¡Œå±è”½å·²ç»çœ‹è¿‡çš„ç”µå½±
        predictions[watched_indices] = -999.0

        # 5. æå–é¢„æµ‹åˆ†æœ€é«˜çš„å‰ N éƒ¨ç”µå½±ç´¢å¼•
        top_indices = np.argsort(predictions)[::-1][:top_n]

        # 6. ç»„è£…è¿”å›ç»“æœ (ä¸ KNN å®Œå…¨ä¸€è‡´çš„å­—å…¸æ ¼å¼)
        results = []
        for idx in top_indices:
            slug = self.movie_slugs[idx]
            score = float(predictions[idx])

            if slug in self.df_movies.index:
                movie_data = self.df_movies.loc[slug]
                results.append({
                    'slug': slug,
                    'title': movie_data['title'],
                    'year': movie_data['year'],
                    'director': movie_data.get('director', ''),
                    'poster_url': movie_data.get('poster_url', ''),
                    'score': score
                })

        return results


# --- æç®€æµ‹è¯•è¿è¡Œ ---
if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ å®é™…çš„æ•°æ®åº“è·¯å¾„
    recommender = AutoRecRecommender("../data/user_first_cut3_clear.db")

    demo_profile = {
        "inception": 5.0,
        "interstellar": 4.5,
        "the-dark-knight": 5.0
    }

    print("--- Deep AutoRec Recommendations ---")
    recommendations = recommender.get_recommendations(demo_profile, top_n=10)

    if not recommendations:
        print("No recommendations found.")
    else:
        for i, rec in enumerate(recommendations, 1):
            print(f"{i}. [{rec['score']:.2f}] {rec['title']} ({rec['year']}) - Dir: {rec['director']}")